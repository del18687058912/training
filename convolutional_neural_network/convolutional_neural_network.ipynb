{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 深度学习（Deep Learning）培训"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## 根本目的：为了找出解决问题的函数。    问题-> **f**-> 解\n",
    "  \n",
    "### 找寻该函数的一种方法：神经网络，它是机器学习的其中一种方法 \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 目录\n",
    "### 神经网络（Neural Networks）\n",
    "### ➡️ 卷积神经网络（Convolutional Neural Networks）⬅️\n",
    "### 循环神经网络（Recurrent Neural Networks）\n",
    "### 生成对抗神经网络（Generative Adversarial Networks）\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 卷积神经网络（Convolutional Neural Networks）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 模型评价和验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 训练集和测试集\n",
    "训练集：用来训练模型\n",
    "测试集：用来评价模型的好坏，永远不能用测试集来训练，也要防止测试集变相泄漏到训练集中。（例如：根据测试集的好坏来调参）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#使用scikit-learn切分数据集\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=np.random.random((4,4))\n",
    "Y=np.random.randint(2,size=(4,1))\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05292897,  0.21407285,  0.7758603 ,  0.36745211],\n",
       "       [ 0.02741381,  0.21345129,  0.34215653,  0.33461939],\n",
       "       [ 0.32562903,  0.74883012,  0.14183651,  0.12779553]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49276782,  0.25756256,  0.79647024,  0.06725042]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 评价分类\n",
    "##### 混淆矩阵（Confusion Matrix）\n",
    "又称为可能性表格或是错误矩阵。可视化的看看分类效果，用来评价分类（Classification）\n",
    "\n",
    "|     |被诊断有病      |被诊断无病     |\n",
    "|---|--------------|--------------|\n",
    "|有病|True Positive |False Negative|\n",
    "|没病|False Positive|True Negative |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "score=accuracy_score(y_true,y_pred) # 0和3是对的，1和2错了，所以0.5\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 评价回归\n",
    "##### 平均绝对误差（Mean Absolute Error）\n",
    "但是有缺点就是无法微分，不能应用梯度下降的误差函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X=np.array([1,2,3,4]).reshape((-1,1)) # 列向量,-1表示自动推理该位置有多少个数\n",
    "Y=np.array([1,2,3,4]).reshape((-1,1)) # 列向量\n",
    "\n",
    "regression=LinearRegression()\n",
    "regression.fit(X,Y)\n",
    "\n",
    "guesses=regression.predict(X)\n",
    "\n",
    "error=mean_absolute_error(Y,guesses)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 均方差（Mean Squared Error）\n",
    "可微分，适合做可梯度下降的误差函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X=np.array([1,2,3,4]).reshape((-1,1)) # 列向量,-1表示自动推理该位置有多少个数\n",
    "Y=np.array([1,2,3,4]).reshape((-1,1)) # 列向量\n",
    "\n",
    "regression=LinearRegression()\n",
    "regression.fit(X,Y)\n",
    "\n",
    "guesses=regression.predict(X)\n",
    "\n",
    "error=mean_squared_error(Y,guesses)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### $R^2$ 决定系数（$R^2$ Score）\n",
    "又叫拟合优度\n",
    "<img src=\"r2_score.jpg\" width=450 height=450 />\n",
    "最简模型的误差是最大的  \n",
    "好的模型：越接近1，因为模型的误差相对于最简模型越小则该项越接近0\n",
    "\n",
    "公式：  \n",
    "If $\\hat{y}_i$ is the predicted value of the i-th sample and y_i is the corresponding true value, then the score R² estimated over $n_{\\text{samples}}$ is defined as\n",
    "\n",
    "$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}} - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\bar{y})^2}$\n",
    "\n",
    "where $\\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} - 1} y_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90785714285714292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_true=np.array([1,2,4])\n",
    "y_pred=np.array([1.3,2.5,3.7])\n",
    "score=r2_score(y_true,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 模型复杂度图（Model Complexity Graph）\n",
    "欠拟合（underfitting）：训练集上表现的不好。 Error due to bias  \n",
    "* 模型小，收到数据影响小，variance比较小，但是可能模拟不到真实情况，bias整个都偏离了正确的   \n",
    "\n",
    "过拟合（overfitting）：训练集上变现的太好，以至于试图记住训练集。 Error due to variance\n",
    "* 模型大，更容易存在符合真实情况的权重使模型符合真实情况，bias更准，但是更容易收到数据带来的误差影响，variance更大\n",
    "\n",
    "<img src=\"error_from_where.jpg\" width=450 height=450 />\n",
    "红色是每次取样后的拟合的线，蓝色是全部红线平均后的线，黑色是真实的\n",
    "<img src=\"error_from_which.jpg\" width=450 height=450 />\n",
    "\n",
    "知道了欠拟合和过拟合的情况，就能运用验证集来挑选模型的拟合程度\n",
    "<img src=\"cross_validation.jpg\" width=450 height=450 />\n",
    "<img src=\"model_complexity_graph.jpg\" width=550 height=550 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### K-Fold Cross Validation\n",
    "<img src=\"k_fold_cross_validation.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3] TEST: [0 1]\n",
      "TRAIN DATA: [[1, 2], [3, 4]] TRAIN LABEL: [3, 4] TEST: [[1, 2], [3, 4]] TEST LABEL: [1, 2]\n",
      "TRAIN: [0 1] TEST: [2 3]\n",
      "TRAIN DATA: [[1, 2], [3, 4]] TRAIN LABEL: [1, 2] TEST: [[1, 2], [3, 4]] TEST LABEL: [3, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=False)  #做两次K-Fold\n",
    "for train_index, test_index in kf.split(X):  #每次取出对应的索引\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(\"TRAIN DATA:\", X_train.tolist(), \"TRAIN LABEL:\",y_train.tolist(), \"TEST:\", X_test.tolist(),\"TEST LABEL:\",y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 文本情感分析\n",
    "[Sentiment Analysis with Numpy](https://github.com/udacity/deep-learning/tree/master/sentiment-network): Andrew Trask leads you through building a sentiment analysis model, predicting if some text is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Intro to TFLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 新的激活函数（Activation functions）\n",
    "Sigmoid作激活函数  \n",
    "缺点：每经过一层，衰减的厉害\n",
    "<img src=\"derivative_sigmoid.jpg\" width=450 height=450 />\n",
    "\n",
    "普通问题：  \n",
    "Rectified Linear Units简称ReLUs作激活函数，用来替代Sigmoid函数，他的微分为1，不会衰减。  \n",
    "公式：  \n",
    "$f(x)=max(x,0)$\n",
    "<img src=\"relu.jpg\" width=450 height=450 />\n",
    "缺点：\n",
    "要控制好learning rate，否则大的梯度会导致ReLUs的神经元的权重变成0，不再对数据有反应，相当于该神经元死亡\n",
    "\n",
    "面对多分类的问题：  \n",
    "通常使用Softmax作最后一层，输出层的激活函数\n",
    "<img src=\"softmax.jpg\" width=450 height=450 />\n",
    "将普通的输出，转化为输出之和为1的概率\n",
    "公式：  \n",
    "$ \\sigma(z)_j = \\frac {e^{z_j}}{\\sum_{k=1}^K e^{z_k}} $ for $ j = 1,...,K $\n",
    "<img src=\"softmax_math.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 新的误差函数（Loss Function）\n",
    "##### 分类交叉熵（Categorical Cross-Entropy）\n",
    "独热码（one-hot encoding）：用来表示目前是多种状态的哪一个状态  \n",
    "如：  \n",
    "标签 $ y = [0,0,0,0,1,0,0,0,0,0] $   \n",
    "预测值 $ \\hat y = [0.047,0.048,0.061,0.07,0.330,0.062,0.001,0.213,0.013,0.150] $\n",
    "\n",
    "交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。\n",
    "公式及计算方法：\n",
    "<img src=\"cross_entropy_calculation.jpg\" width=450 height=450 />\n",
    "\n",
    "分类交叉熵经常和输出层是Softmax配套使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 简单的情感分析技巧\n",
    "##### Bag of Words\n",
    "\"the fox jumps over the lazy dog\"   \n",
    "分解成，键值对，键为词，值为出现个数：{'the': 2, 'jumps': 1, 'lazy': 1, 'over': 1, 'fox': 1, 'dog': 1}   \n",
    "缺点是损失order of words\n",
    "##### Word2vec\n",
    "continuous bag of words (CBOW) and Skip grams  \n",
    "Skip grams：利用神经网络来训练词的向量表示，方法是：输入神经网络的一个单词预测周围的n个词。   \n",
    "训练结果具备线性相关的属性\n",
    "<img src=\"word2vec_matrix.jpg\" width=450 height=450 />\n",
    "<img src=\"word2vec_linear.jpg\" width=450 height=450 />\n",
    "##### RNN（Recurrent Neural Network）\n",
    "适合处理序列，如text和audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Intro to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called tensor\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### TensorFlow基础\n",
    "##### Tensor\n",
    "TensorFlow里的数据都用Tensor对象表示\n",
    "\n",
    "* 常量用tf.constant()\n",
    "* 占位符用tf.placeholder()，占位符用于运行前填入数据\n",
    "* 变量用tf.Variable()\n",
    "##### Session\n",
    "运行时的上下文环境，运行后输出Tensor的结果\n",
    "##### TensorFlow Math\n",
    "* tf.add()\n",
    "* tf.subtract()\n",
    "* tf.multiply()\n",
    "* tf.divide()\n",
    "* tf.cast()   例：tf.cast(tf.constant(2.0), tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 基于TensorFlow构造神经网络做手写数字的分类\n",
    "#### 第一种神经网络：普通神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 数据集\n",
    "[MNIST数据集](http://yann.lecun.com/exdb/mnist/)：手写识别数字及其标签的数据集\n",
    "<img src=\"MNIST_Matrix.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 神经网络构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "输入层：  \n",
    "输入是28 \\* 28的矩阵  \n",
    "标签是1 \\* 9的One hot encoding向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_features = 28*28\n",
    "n_labels = 9\n",
    "x = tf.placeholder(tf.float32,(1,n_features)) # 横向量 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "隐含层：暂不带上激活函数  \n",
    "线性方程：$ y = xW + b $  \n",
    "这里：x输入，W是权值，b是偏差  \n",
    "方程用TensorFlow表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal((n_features, n_labels)))  \n",
    "b = tf.Variable(tf.zeros(n_labels))  \n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "输出层：Softmax做激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output=tf.placeholder(tf.float32)\n",
    "softmax=tf.nn.softmax(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "误差函数：交叉熵  $ D(\\hat y , y) = - \\sum_j y_j ln\\hat y_j $\n",
    "<img src=\"cross_entropy_calculation.jpg\" width=300 height=300 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_hot=tf.placeholder(tf.float32)\n",
    "cross_entropy = tf.multiply(-1.0, tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 训练神经网络的技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 归一化输入和初始化权值（Normalized Inputs and Initial Weights）\n",
    "<img src=\"Mean_Variance_Image.png\" width=450 height=450 />\n",
    "输入值要进行归一化   \n",
    "权值要用正态分布随机取值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 衡量训练效果  \n",
    "训练集  \n",
    "验证集  \n",
    "测试集  \n",
    "误区：发现测试集效果不好就回头调参数，这样相当于用测试集来训练模型了，永远只在最后用测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 训练方法：随机梯度下降（Stochastic Gradient Descent）\n",
    "<img src=\"stochastic_gradient_descent.jpg\" width=450 height=450 />\n",
    "\n",
    "直接使用全部数据做梯度下降虽然下降的方向很准，但是量太大很难计算走一步太慢，还可能爆内存。   \n",
    "所以这里随机抽样一个数据出来算梯度下降近似替代。  \n",
    "这种方法可适用于大模型大数据量，应用范围广泛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Mini-batch SGD\n",
    "每次抽样一部分数据来计算梯度下降做近似\n",
    "\n",
    "[各种SGD比较](http://www.cnblogs.com/richqian/p/4549590.html)   \n",
    "batch、mini-batch、SGD、online的区别在于训练数据的选择上  \n",
    "\n",
    "| |batch|\tmini-batch|\tStochastic|\tOnline|\n",
    "|--|--|--|--|--|\n",
    "|训练集|\t固定|\t固定|\t固定|\t实时更新|\n",
    "|单次迭代样本数|\t整个训练集|\t训练集的子集|\t单个样本|\t根据具体算法定|\n",
    "|算法复杂度|\t高|\t一般|\t低|\t低|\n",
    "|时效性|\t低|\t一般（delta 模型）|\t一般（delta 模型）|\t高|\n",
    "|收敛性|\t稳定|\t较稳定|\t不稳定\t|不稳定|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 12.5     Valid Accuracy: 0.108\n",
      "Epoch: 1    - Cost: 11.5     Valid Accuracy: 0.123\n",
      "Epoch: 2    - Cost: 10.9     Valid Accuracy: 0.139\n",
      "Epoch: 3    - Cost: 10.4     Valid Accuracy: 0.153\n",
      "Epoch: 4    - Cost: 9.88     Valid Accuracy: 0.168\n",
      "Epoch: 5    - Cost: 9.45     Valid Accuracy: 0.183\n",
      "Epoch: 6    - Cost: 9.05     Valid Accuracy: 0.197\n",
      "Epoch: 7    - Cost: 8.67     Valid Accuracy: 0.212\n",
      "Epoch: 8    - Cost: 8.32     Valid Accuracy: 0.225\n",
      "Epoch: 9    - Cost: 7.99     Valid Accuracy: 0.239\n",
      "Test Accuracy: 0.24040000140666962\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('./mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 训练代数（Epochs）\n",
    "每代表示全部数据走了一边"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 训练技巧\n",
    "训练时：\n",
    "* 学习率衰减\n",
    "* 防止卡在局部最优，可用动量，记录每次梯度的值做平均后在选梯度下降的方向。\n",
    "* 学习率的选择：小的也可能更快\n",
    "<img src=\"learning_rate_tuning.jpg\" width=450 height=450>\n",
    "* 超参数的选择有点黑魔法，凭借经验，最好用的一个方法是：如果觉得效果不好，就降低学习率试试。\n",
    "* 为了降低调参的数量，可用ADAGRAD（一种SGD的变种），自带动量和学习率衰减的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "课后练习：[Lab:TensorFlow Neural Network](https://github.com/udacity/deep-learning/tree/master/intro-to-tensorflow) 查看ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 第二种神经网络：卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "当你知道处理的是图像时，卷积神经网络最擅长处理图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 统计的不变性（Statistical Invariance）\n",
    "主要想说明，图像中的元素在图像的哪个位置不重要，只要能找出他识别出来即可。\n",
    "<img src=\"image_cat.jpg\" width=300 height=300 />\n",
    "\n",
    "要在神经网络里实现这种效果，要用到权值共享（Weight Sharing），猫不管在哪个位置他的权值都是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 卷积神经网络（Convolutional Neural Network）简称CovNet\n",
    "##### 简介\n",
    "图像的表示：\n",
    "<img src=\"image_representation.jpg\" width=300 height=300 />\n",
    "\n",
    "用一个小的Filter去扫描图像，filter中的weights不变，会得到一个新图像，这种操作就是卷积（Convolutions）\n",
    "<img src=\"covnet_filter.jpg\" width=300 height=300 />\n",
    "<img src=\"covnet_convolutions.jpg\" width=450 height=450 />\n",
    "卷积神经网络就是不断的做卷积叠加起来的神经网络，缩小长宽，加深深度，越深表示的信息越多\n",
    "<img src=\"covnet.jpg\" width=500 height=500 />\n",
    "最终结果放入普通的神经网络做softmax分类\n",
    "\n",
    "一些术语：  \n",
    "patch：filter的扫描的面积\n",
    "<img src=\"covnet_patch.jpg\" width=450 height=450 />\n",
    "featured map: 每个深度所表示的图像\n",
    "<img src=\"covnet_featured_map.jpg\" width=450 height=450 />\n",
    "stride: filter扫描时的步长，决定卷积后的图像的大小\n",
    "<img src=\"covnet_stride.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_stride_2.jpg\" width=450 height=450 />\n",
    "valid padding:filter扫描时不填充边缘\n",
    "<img src=\"covnet_valid_padding.jpg\" width=450 height=450 />\n",
    "same padding:filter扫描时填充边缘，使卷积后的图像同长宽\n",
    "<img src=\"covnet_same_padding.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 直观来讲：  \n",
    "每层卷积会识别图像的一种特征，更高的卷积会识别出组合后更高级的特征。  \n",
    "人也是，从最基础的特征识别，比如狗的鼻子、嘴巴，再到狗脸，最后是整个狗。\n",
    "<img src=\"covnet_intuition.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN的核心Filter\n",
    "<img src=\"covnet_convolution_detail.jpg\" width=450 height=450 />\n",
    "Filter用Patch这么大的面积去扫整个图像，Patch里每个像素的权值是一样的（Weights Sharing），每次扫到的Patch里的像素归到一个神经元管理，\n",
    "<img src=\"covnet_filter_scan.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_filter_scan_2.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_filter_group.jpg\" width=450 height=450 />\n",
    "每一次扫描相当于把框框内的东西组合成一个神经元\n",
    "<img src=\"covnet_filter_detail.jpg\" width=300 height=300 />\n",
    "Filter的k表示抽取的特性的个数\n",
    "\n",
    "注意：如果不用卷积Filter的方式取归组像素，那相当于每个像素都要连接一个神经元，网络非常大根本无法学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习题  \n",
    "Setup  \n",
    "H = height, W = width, D = depth  \n",
    "* We have an input of shape 32x32x3 (HxWxD)  \n",
    "* 20 filters of shape 8x8x3 (HxWxD)  \n",
    "* A stride of 2 for both the height and width (S)  \n",
    "* Zero padding of size 1 (P)  \n",
    "\n",
    "Output Layer  \n",
    "* 14x14x20 (HxWxD)\n",
    "\n",
    "Q1 How many parameters does the convolutional layer have (without parameter sharing)?  \n",
    "Q2 How many parameters does the convolution layer have (with parameter sharing)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 卷积神经网络的结构\n",
    "<img src=\"covnet_full.jpg\" width=450 height=450 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可视化卷积神经网络\n",
    "[Visualizing and Understanding Convolutional Networks](http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf)\n",
    "\n",
    "<img src=\"covnet_visualize_layer1.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_visualize_layer2.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_visualize_layer3.jpg\" width=450 height=450 />\n",
    "<img src=\"covnet_visualize_layer5.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TensorFlow实现CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
