{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 深度学习（Deep Learning）培训"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 根本目的：为了找出解决问题的函数。    问题-> **f**-> 解\n",
    "  \n",
    "### 找寻该函数的一种方法：神经网络，它是机器学习的其中一种方法 \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 目录\n",
    "### 神经网络（Neural Networks）\n",
    "### 卷积神经网络（Convolutional Neural Networks）\n",
    "### ➡️ 循环神经网络（Recurrent Neural Networks）⬅️\n",
    "### 生成对抗神经网络（Generative Adversarial Networks）\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 循环神经网络（Recurrent Neural Networks）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 循环神经网络入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 循环神经网络结构\n",
    "<img src=\"rnn_steep.jpg\" height=450 width=450>\n",
    "普通的神经网络不能记录上下文的关系，而用循环神经网络因为一个样本的输出会影响下一个样本的输入，所以经过训练后能理解上下文之间关系。\n",
    "\n",
    "比如STEEP这个单词，普通神经网络是碰到E这个单词作为输入时，就懵逼了，不知道输出应该是E还是P。\n",
    "但是循环神经网络，因为知道上一个输入的是T，得知此时应该输出E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 循环神经网络展开\n",
    "<img src=\"rnn_unroll.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环神经网络实例\n",
    "<img src=\"rnn_instance.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 普通循环神经网络的缺点\n",
    "<img src=\"rnn_drawback.jpg\" width=450 height=450 />\n",
    "因为每层的权重和该层上一个循环的权重相乘，上下文越长，循环层次越深，相乘越多，若小于0则越来越小而消失，若大于0则权重越来越大而爆炸。\n",
    "<img src=\"rnn_drawback_plot.jpg\" width=450 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环神经网络的改进 - LSTM\n",
    "<img src=\"rnn_cell.jpg\" width=450 height=450 />\n",
    "把每个循环层当作一个整体，称为cell，设计cell的结构避免梯度消失或爆炸的问题\n",
    "##### LSTM\n",
    "<img src=\"rnn_lstm.jpg\"  width=450 height=450 />\n",
    "* 新增了一个cell state\n",
    "* 四个黄色的激活函数表示四个神经元块，每个都有各自的权重\n",
    "* 四个红色操作符的表示element-wise的操作\n",
    "##### LSTM Cell State\n",
    "<img src=\"rnn_lstm_cell_state.jpg\"  width=450 height=450 />\n",
    "Cell State流通每层的信息，被红色操作符修改\n",
    "##### LSTM Forget Gate\n",
    "<img src=\"rnn_lstm_forget_gate.jpg\"  width=450 height=450 />\n",
    "Sigmoid趋近于0，则忘记该信息，趋近于1则保留该信息。这样网络就能决定记住还是忘记某些信息。\n",
    "##### LSTM Update State\n",
    "<img src=\"rnn_lstm_update_state.jpg\"  width=450 height=450 />\n",
    "根据前一循环层输出和当前循环层输入来个更新Cell State。这里的Sigmoid同样用于保留还是忘记信息。\n",
    "##### LSTM Cell State to Hidden Output\n",
    "<img src=\"rnn_lstm_cell_state_hidden_output.jpg\"  width=450 height=450 />\n",
    "生成输出传入下一个循环层。这里的Sigmoid同样用于保留还是忘记信息。\n",
    "##### LSTM fix RNN Drawback\n",
    "<img src=\"rnn_lstm_structure.jpg\"  width=450 height=450 />\n",
    "Sigmoid开关让信息不会爆炸\n",
    "\n",
    "详细阅读：   \n",
    "[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)   \n",
    "[[译] 理解 LSTM 网络](http://www.jianshu.com/p/9dc9f41f0b29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
